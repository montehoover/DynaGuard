# Inference (consider separate env to avoid CUDA clashes)
vllm==0.7.3

# Core model/training stack
torch
transformers==4.51.0
accelerate
trl
datasets
scikit-learn 
peft

# GPU add-ons (remove on CPU-only)
xformers
bitsandbytes

# Data & numeric
numpy
pandas
matplotlib

# Providers
openai
litellm
wandb
